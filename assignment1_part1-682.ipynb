{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "757b4bc40ae9b28ccfad873662d95388",
     "grade": false,
     "grade_id": "cell-fc9b2593ea47645a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Social Media Analytics\n",
    "## School of Information, University of Michigan\n",
    "\n",
    "## Week 1: \n",
    " \n",
    "- Intro to social data: types of data, platforms, profiles\n",
    "- Ethical considerations in working with social media data\n",
    "- Intro to platform APIs: obtaining and managing data\n",
    "- Understanding the structure of social platform data\n",
    "\n",
    "\n",
    "## Assignment Overview\n",
    "### The objective of this assignment is to:\n",
    "\n",
    "- Access social platform data using an API\n",
    "    - figure out how to get and use authentication credentials\n",
    "- Manipulate the data accessed using python\n",
    "\n",
    "### The total score of this assignment will be 100 points consisting of:\n",
    "\n",
    "- retrieve one tweet: 20 points\n",
    "- retrieve one follower: 20 points\n",
    "- `create_tweet_df` function: 20 points\n",
    "- `create_hashtag_df` function: 20 points\n",
    "- `create_weekday_hour_count_df` function: 20 points\n",
    "\n",
    "### Resources:\n",
    "\n",
    " - [Tweepy API documentation (v4.10.0 is used for this assignment)](https://docs.tweepy.org/en/v4.10.0/index.html)\n",
    " - [Tweepy Getting Started Tutorial](https://docs.tweepy.org/en/v4.10.0/getting_started.html)\n",
    " - [Twitter API documentation](https://developer.twitter.com/en/docs/api-reference-index) \n",
    "\n",
    "### Instructions: \n",
    "In the first part of this assignment, you will use the Twitter API, Tweepy, and the Twitter API documentation to guide you through the process of obtaining social platform data. Once obtained, you will manipulate the data using Python to explore the types of data found on social platforms and the way in which those data are structured. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2fb3e48b3d9aeb9f3dbf75fc29e5be86",
     "grade": false,
     "grade_id": "jupyter",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "---\n",
    "## Part A (100 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f936def11c0de484dd9d675e09b7dc38",
     "grade": false,
     "grade_id": "cell-4879da2e3ba6125f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Important Note\n",
    "You can execute calls to Twitter's API in your notebook. The autograder **can not**.\n",
    "\n",
    "To get around this limitation, we ask you for the first two problems to *paste a text string that is extracted from the results of a call to the Twitter API*.\n",
    "\n",
    "Once you have run your code that produces the string that you need, you should comment out your code that produced it. **If you don't comment out your code that makes Twitter API calls, the auto-grader will fail and won't score the rest of your cells**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6165f324e4865a9ca35875e4cb51d258",
     "grade": true,
     "grade_id": "cell-c5589e1c99c131b2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "\n",
    "consumer_key = 'rMdn4OpQLle1iqOkzeGoGwXTs'\n",
    "consumer_secret = 'VO8AQtsVvZwssSxwk5uSIZQdxbBJjHUySdOrXyqLuV7HjENwfV'\n",
    "access_token = '1075512862964150272-WoLvl5PLVOnWtltQpVNndKZRRTbdV2'\n",
    "access_token_secret = 'uszwZzyott40XgFnC5S7sFt9zcqcJHNX4q1axHXfqIdCL'  \n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94da3d7ae62c029de5099c43634e3a0a",
     "grade": false,
     "grade_id": "cell-9790021ad923d3f2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Get the data for one tweet as a json-formatted string\n",
    "20 points\n",
    "1. Call Twitter's API to get data for a single tweet\n",
    "    - One way is to make an API request for a single tweet. You can find one using the twitter website (check the URL string).\n",
    "    - Alternately, you can use an API call that returns data for multiple tweets. But be sure that you extract just a single one.\n",
    "2. Serialize the python object as a JSON formatted string, print it out, and copy the string literal\n",
    "    - Hint: json.dumps\n",
    "    \n",
    "3. Save it to a variable called `tweet_data_string`. Note that you will need to assign a hard-coded string literal to this variable, the string that you copied in the previous step.\n",
    "\n",
    "Note: the example provided shows only a few fields on the tweet object. Your solution should include all the fields that the \n",
    "          tweet json includes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e2f3bca863b91f1f8f9e2d80f6259d8c",
     "grade": false,
     "grade_id": "tweet_sample",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "results = api.search_tweets(q=\"@TheRock\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data_string = json.dumps(results._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f25e8e3d9ae285916dbf9e634753562b",
     "grade": true,
     "grade_id": "tweet_sample_test",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Some tests for your code in the previous cell. \n",
    "# There are additional hidden tests not shown in this cell that the autograder uses.\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n",
    "schema = '{\"definitions\": {}, \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"http://example.com/root.json\", \"type\": \"object\", \"additionalProperties\": true, \"title\": \"The Root Schema\", \"required\": [\"created_at\", \"id\", \"id_str\"], \"properties\": {\"created_at\": {\"$id\": \"#/properties/created_at\", \"type\": \"string\", \"title\": \"The Created_at Schema\", \"default\": \"\", \"examples\": [\"Wed Nov 20 14:14:20 +0000 2019\"], \"pattern\": \"^(.*)$\"}, \"id\": {\"$id\": \"#/properties/id\", \"type\": \"integer\", \"title\": \"The Id Schema\", \"default\": 0, \"examples\": [1197156225588301800]}, \"id_str\": {\"$id\": \"#/properties/id_str\", \"type\": \"string\", \"title\": \"The Id_str Schema\", \"default\": \"\", \"examples\": [\"1197156225588301824\"], \"pattern\": \"^(.*)$\"}}}'\n",
    "validation_schema = json.loads(schema)\n",
    "sample = json.loads(tweet_data_string)\n",
    "raised = False\n",
    "try:\n",
    "    validate(sample, schema=validation_schema)\n",
    "except:\n",
    "    raised = True\n",
    "assert raised == False, 'tweet_data_string, Json schema is not correct'\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e075d38ba86639aaec68d42fe8568b8b",
     "grade": false,
     "grade_id": "cell-558ca9d0397196cf",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Get the data for a single follower of the umsi twitter account\n",
    "\n",
    "20 points.\n",
    "\n",
    "Again, dump it out as a json formatted string, print it, and paste it as a string literal assigning it to the variable `follower_data_as_string`. Don't forget to comment out your code that makes Twitter API calls.\n",
    "\n",
    "Note: you should paste the data for just a single follower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "follower_data_as_string = json.dumps(api.get_followers(screen_name = \"@umsi\")[0]._json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ec1dd2b1b002859f3ff43f62ce9525aa",
     "grade": false,
     "grade_id": "follower_sample",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# replace the string literal below\n",
    "#follower_data_as_string = '{\"id\": 18033550, \"id_str\": \"18033550\", \"name\": \"School of Information\"}'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3b18a18f43d381468cfaed8ba23c3219",
     "grade": true,
     "grade_id": "follower_sample_test",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Some tests for your code in the previous cell. \n",
    "# There are additional hidden tests not shown in this cell that the autograder uses.\n",
    "submission = follower_data_as_string\n",
    "assert type(submission) == str, 'follower_sample, function does not return a json string.'\n",
    "\n",
    "converted = json.loads(submission)\n",
    "assert type(converted) == dict, 'follower_sample, json string does not contain a dictionary response.'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab591925982c711255bf91ca31bca37b",
     "grade": false,
     "grade_id": "cell-402a3615a2afe448",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Using Cached Data\n",
    "The remaining questions will have you process data of the kind that comes back from Twitter.\n",
    "\n",
    "So that you are working with the same data that our auto-grader is, you will be processing data that we have already retrieved and saved in a text file.\n",
    "\n",
    "In other words, congratulations on establishing that you can use the Twitter API to fetch data. But from here on out, you won't be using it for the graded assignments; you'll only be using data that we've already fetched and saved in files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd8f87299defc9d4d0ff255b2a89d890",
     "grade": false,
     "grade_id": "create_tweet_df",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "def create_tweet_df(json_file_path):\n",
    "    \"\"\" 20 points\n",
    "        Transform the tweets_json object into a dataframe with the following columns and dataypes:\n",
    "        'retweet_count', int64\n",
    "        'created_at', datetime64[ns, UTC]\n",
    "        'full_text', object\n",
    "        'favorited', bool\n",
    "        'retweeted', bool\n",
    "        'lang', object\n",
    "        'favorite_count', int64\n",
    "        \n",
    "        Return the dataframe\n",
    "    \"\"\" \n",
    "    return pd.read_json(json_file_path)[[\"retweet_count\", \"created_at\", \"full_text\", \"favorited\", \"retweeted\", \"lang\", \"favorite_count\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>created_at</th>\n",
       "      <th>full_text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorite_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5069</td>\n",
       "      <td>2020-01-28 21:20:27+00:00</td>\n",
       "      <td>RT @realDonaldTrump: https://t.co/tvvvnGEmjo h...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>und</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2502</td>\n",
       "      <td>2020-01-28 19:34:00+00:00</td>\n",
       "      <td>RT @WhiteHouse: \"All humanity should be able t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1170</td>\n",
       "      <td>2020-01-28 19:05:57+00:00</td>\n",
       "      <td>RT @WhiteHouse: \"Perhaps most importantly, my ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1174</td>\n",
       "      <td>2020-01-28 18:50:45+00:00</td>\n",
       "      <td>RT @WhiteHouse: \"We must break free of yesterd...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1732</td>\n",
       "      <td>2020-01-28 18:50:45+00:00</td>\n",
       "      <td>RT @WhiteHouse: On Sunday, President @realDona...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>5674</td>\n",
       "      <td>2019-03-07 22:05:56+00:00</td>\n",
       "      <td>RT @FLOTUS: It was wonderful to welcome the Pr...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>2853</td>\n",
       "      <td>2019-03-07 21:21:02+00:00</td>\n",
       "      <td>RT @FLOTUS: Honored to celebrate a group of ex...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3198</th>\n",
       "      <td>27347</td>\n",
       "      <td>2019-03-07 14:40:32+00:00</td>\n",
       "      <td>RT @realDonaldTrump: We are on track to APPREH...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>2940</td>\n",
       "      <td>2019-03-07 14:21:03+00:00</td>\n",
       "      <td>RT @WhiteHouse: .@IvankaTrump: “The mission of...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>39125</td>\n",
       "      <td>2019-03-07 00:07:37+00:00</td>\n",
       "      <td>RT @realDonaldTrump: Democrats just blocked @F...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3201 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      retweet_count                created_at  \\\n",
       "0              5069 2020-01-28 21:20:27+00:00   \n",
       "1              2502 2020-01-28 19:34:00+00:00   \n",
       "2              1170 2020-01-28 19:05:57+00:00   \n",
       "3              1174 2020-01-28 18:50:45+00:00   \n",
       "4              1732 2020-01-28 18:50:45+00:00   \n",
       "...             ...                       ...   \n",
       "3196           5674 2019-03-07 22:05:56+00:00   \n",
       "3197           2853 2019-03-07 21:21:02+00:00   \n",
       "3198          27347 2019-03-07 14:40:32+00:00   \n",
       "3199           2940 2019-03-07 14:21:03+00:00   \n",
       "3200          39125 2019-03-07 00:07:37+00:00   \n",
       "\n",
       "                                              full_text  favorited  retweeted  \\\n",
       "0     RT @realDonaldTrump: https://t.co/tvvvnGEmjo h...      False      False   \n",
       "1     RT @WhiteHouse: \"All humanity should be able t...      False      False   \n",
       "2     RT @WhiteHouse: \"Perhaps most importantly, my ...      False      False   \n",
       "3     RT @WhiteHouse: \"We must break free of yesterd...      False      False   \n",
       "4     RT @WhiteHouse: On Sunday, President @realDona...      False      False   \n",
       "...                                                 ...        ...        ...   \n",
       "3196  RT @FLOTUS: It was wonderful to welcome the Pr...      False      False   \n",
       "3197  RT @FLOTUS: Honored to celebrate a group of ex...      False      False   \n",
       "3198  RT @realDonaldTrump: We are on track to APPREH...      False      False   \n",
       "3199  RT @WhiteHouse: .@IvankaTrump: “The mission of...      False      False   \n",
       "3200  RT @realDonaldTrump: Democrats just blocked @F...      False      False   \n",
       "\n",
       "     lang  favorite_count  \n",
       "0     und               0  \n",
       "1      en               0  \n",
       "2      en               0  \n",
       "3      en               0  \n",
       "4      en               0  \n",
       "...   ...             ...  \n",
       "3196   en               0  \n",
       "3197   en               0  \n",
       "3198   en               0  \n",
       "3199   en               0  \n",
       "3200   en               0  \n",
       "\n",
       "[3201 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_path = \"assets/POTUS_2019-03-07_2020-01-28.json\"\n",
    "df = create_tweet_df(json_file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cf1a0fecf3285be6bf87beb9c5cb0acf",
     "grade": true,
     "grade_id": "create_tweet_df_test",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Some tests for your code in the previous cell. \n",
    "# There are additional hidden tests not shown in this cell that the autograder uses.\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = create_tweet_df('assets/POTUS_2019-03-07_2020-01-28.json')\n",
    "df_length = 3201\n",
    "assert len(df) == df_length, \"create_tweet_df, the length of the dataframe should be %d\" % df_length\n",
    "df_cols = ['retweet_count','created_at','full_text','favorited','retweeted','lang','favorite_count','retweet_count']\n",
    "for col_name in df_cols:\n",
    "    assert col_name in df.columns.values, \"create_tweet_df, the column %s should be included\" % col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b99ac18785d2502f6f816f43f3213e5",
     "grade": false,
     "grade_id": "create_hashtag_df",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "def create_hashtag_df(json_file_path):\n",
    "    \"\"\" 20 points\n",
    "        Transform the tweets_json object into a dataframe with the following columns:\n",
    "        'text', object, the text of the hashtag\n",
    "        'user', object, the screen name of the user who tweeted; if it's a retweet then the retweeter, not the original tweeter\n",
    "        'created_at', datetime, the time the hashtag was tweeted\n",
    "        HINT: Use the entities.hashtags attribute in the tweet to build this dataframe\n",
    "    \"\"\" \n",
    "    df = pd.read_json(json_file_path)\n",
    "    tags = []\n",
    "    for i,row in df.iterrows():\n",
    "        user = row[\"user\"][\"screen_name\"]\n",
    "        created_at = row[\"created_at\"]\n",
    "        for tag in row[\"entities\"][\"hashtags\"]:\n",
    "            tags.append({\"text\":tag[\"text\"], \"user\":user, \"created_at\":created_at})\n",
    "\n",
    "    return pd.DataFrame(tags) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_path = \"assets/POTUS_2019-03-07_2020-01-28.json\"\n",
    "hashtags = create_hashtag_df(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "129ccc51e9396c12eac974a00ad7d387",
     "grade": true,
     "grade_id": "create_hashtag_df_test",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Some tests for your code in the previous cell. \n",
    "# There are additional hidden tests not shown in this cell that the autograder uses.\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = create_hashtag_df('assets/POTUS_2019-03-07_2020-01-28.json')\n",
    "df_length = 86\n",
    "assert len(df) == df_length, \"create_hashtag_df, the length of the dataframe should be %d\" % df_length\n",
    "df_cols = ['text','user','created_at']\n",
    "for col_name in df_cols:\n",
    "    assert col_name in df.columns.values, \"create_hashtag_df, the column %s should be included\" % col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb58257d5795db6c7f3a7d91645efac9",
     "grade": false,
     "grade_id": "create_weekday_hour_count_df",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "def create_weekday_hour_count_df(tweets_dataframe):\n",
    "    \"\"\" 20 points\n",
    "        Create a pivot table where the columns are the day hours (0 -23) \n",
    "        and rows are weekdays ('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday').\n",
    "        Each cell would be the count of tweets at a given weekday and a given hour.\n",
    "        If there are no values at a specific weekday and hour the value should be 0\n",
    "        Sort the hours in ascending order starting from 0 and the weekdays starting from Monday\n",
    "    \"\"\"\n",
    "    df = tweets_dataframe.copy()\n",
    "    df[\"hour\"] = df[\"created_at\"].dt.hour\n",
    "    df[\"dow\"] = df[\"created_at\"].dt.day_name()\n",
    "    pt = df.pivot_table(values=\"created_at\", index=\"dow\", columns=\"hour\", aggfunc=\"count\").fillna(0).loc[[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]]\n",
    "    for t in range(24):\n",
    "        if t not in pt.columns:\n",
    "            pt.insert(t, t, [0.0]*len(pt))\n",
    "    return pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_at\n",
       "2019-03-07 21:00:00+00:00    1\n",
       "2019-03-07 22:00:00+00:00    0\n",
       "2019-03-07 23:00:00+00:00    0\n",
       "2019-03-08 00:00:00+00:00    0\n",
       "2019-03-08 01:00:00+00:00    0\n",
       "                            ..\n",
       "2020-01-22 12:00:00+00:00    0\n",
       "2020-01-22 13:00:00+00:00    0\n",
       "2020-01-22 14:00:00+00:00    0\n",
       "2020-01-22 15:00:00+00:00    0\n",
       "2020-01-22 16:00:00+00:00    1\n",
       "Freq: H, Name: dow, Length: 7700, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"hour\"] = df[\"created_at\"].dt.hour\n",
    "df[\"dow\"] = df[\"created_at\"].dt.day_name()\n",
    "df.set_index(\"created_at\").resample(\"1h\")[\"dow\"].agg(\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ad4364390371dd58f308febe14c9909",
     "grade": true,
     "grade_id": "cell-create_weekday_hour_count_df_test",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Some tests for your code in the previous cell. \n",
    "# There are additional hidden tests not shown in this cell that the autograder uses.\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "t_df = create_tweet_df('assets/POTUS_2019-03-07_2020-01-28.json')\n",
    "df = create_weekday_hour_count_df(t_df)\n",
    "for col_name in range(0,24):\n",
    "    assert col_name in df.columns.values, \"create_weekday_hour_count_df, the column %s should be included\" % col_name\n",
    "for row_name in ['Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday','Wednesday']:\n",
    "    assert row_name in df.index.values, \"create_weekday_hour_count_df, the column %s should be included\" % row_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_social_media_analytics_v2_assignment1_part1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
